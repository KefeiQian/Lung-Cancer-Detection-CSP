{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import shutil\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (512, 512)\n",
    "\n",
    "test_subset_id = 9\n",
    "\n",
    "output_folder = \"output/\"\n",
    "work_data_folder = \"data/\"\n",
    "\n",
    "detections_output_path = \"output/detections\"\n",
    "\n",
    "image_folder_path = \"../data/images\"\n",
    "\n",
    "for folder in [output_folder, work_data_folder, detections_output_path]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_detection_result():\n",
    "    detection_result_folder = \"../output/valresults/caltech/hw/off\"\n",
    "\n",
    "    detection_dfs = {}\n",
    "    for epoch_id in tqdm(os.listdir(detection_result_folder), desc=\"test epoch\"):\n",
    "        current_folder_path = \"{}/{}\".format(detection_result_folder, epoch_id)\n",
    "\n",
    "        detection_dfs.setdefault(epoch_id, {})\n",
    "        for filename in os.listdir(current_folder_path):\n",
    "            series_id = filename[0:-4]\n",
    "            file = os.path.join(current_folder_path, filename)\n",
    "\n",
    "            try:\n",
    "                result_df = pd.read_csv(file, delimiter=\" \", header=None)\n",
    "                result_df.columns = [\"z-index\", \"top_left_x\", \"top_left_y\", \"width\", \"height\", \"probability\"]\n",
    "                detection_dfs.get(epoch_id).setdefault(series_id, result_df)\n",
    "            except Exception:\n",
    "                # print(epoch_id, filename, \"skipped\")\n",
    "                empty_df = pd.DataFrame()\n",
    "                detection_dfs.get(epoch_id).setdefault(series_id, empty_df)\n",
    "\n",
    "    return detection_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_detections = read_detection_result()\n",
    "# test_detections[\"001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_to_voxel_coord(world_coord, origin, spacing):\n",
    "    stretched_voxel_coord = np.absolute(world_coord - origin)\n",
    "    voxel_coord = stretched_voxel_coord / spacing\n",
    "    return voxel_coord\n",
    "\n",
    "\n",
    "def read_ground_truth_data():\n",
    "    fid = open(\"../data/cache/test\", 'rb')\n",
    "    test_pickle = pickle.Unpickler(fid, encoding=\"latin1\")\n",
    "    test_cache = test_pickle.load()\n",
    "\n",
    "    gt_df = pd.DataFrame(test_cache)\n",
    "    gt_df[\"series_id\"] = gt_df[\"filepath\"].map(lambda x: x.split(\"/\")[-2])\n",
    "    gt_df[\"z-index\"] = gt_df[\"filepath\"].map(lambda x: int(x.split(\"/\")[-1][2:-4]))\n",
    "\n",
    "    return gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = read_ground_truth_data()\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap_area_ratio(a, b):\n",
    "    a_top_left_x, a_top_left_y, a_bottom_right_x, a_bottom_right_y = a\n",
    "    b_top_left_x, b_top_left_y, b_bottom_right_x, b_bottom_right_y = b\n",
    "\n",
    "    overlap_width = min(a_bottom_right_x, b_bottom_right_x) - max(a_top_left_x, b_top_left_x)\n",
    "    if overlap_width <= 0:\n",
    "        return 0\n",
    "\n",
    "    overlap_height = min(a_bottom_right_y, b_bottom_right_y) - max(a_top_left_y, b_top_left_y)\n",
    "    if overlap_height <= 0:\n",
    "        return 0\n",
    "\n",
    "    a_area = (a_bottom_right_x - a_top_left_x) * (a_bottom_right_y - a_top_left_y)\n",
    "    b_area = (b_bottom_right_x - b_top_left_x) * (b_bottom_right_y - b_top_left_y)\n",
    "\n",
    "    overlap_area = overlap_width * overlap_height\n",
    "    total_area = a_area + b_area - overlap_area\n",
    "\n",
    "    overlap_ratio = overlap_area / total_area\n",
    "    return overlap_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_threshold = 0.05\n",
    "\n",
    "def calculate_mr(threshold = 0.5):\n",
    "    for epoch_id in tqdm(test_detections.keys(), desc=\"epoch\"):\n",
    "        epoch_test_result = test_detections[epoch_id]\n",
    "\n",
    "        hit_counter = 0\n",
    "\n",
    "        number_of_test = 0\n",
    "\n",
    "        detections_output_folder = \"{}/{}\".format(detections_output_path, epoch_id)\n",
    "        if not os.path.exists(detections_output_folder):\n",
    "            os.makedirs(detections_output_folder)\n",
    "        else:\n",
    "            shutil.rmtree(detections_output_folder)\n",
    "\n",
    "        for series_id in epoch_test_result.keys():\n",
    "            image_detections = epoch_test_result[series_id]\n",
    "            if len(image_detections) == 0:\n",
    "                continue\n",
    "            image_detections[\"z-index\"] = image_detections[\"z-index\"].map(lambda x: round(x))\n",
    "            image_detections[\"bottom_right_x\"] = image_detections[\"top_left_x\"] + image_detections[\"width\"]\n",
    "            image_detections[\"bottom_right_y\"] = image_detections[\"top_left_y\"] + image_detections[\"height\"]\n",
    "            image_detections[\"bbox\"] =  list(image_detections[['top_left_x', 'top_left_y', \"bottom_right_x\", \"bottom_right_y\"]].to_records(index=False))\n",
    "\n",
    "            nodules = annotations[annotations[\"series_id\"] == series_id]\n",
    "\n",
    "            for i, nodule in nodules.iterrows():\n",
    "                z_index = nodule[\"z-index\"]\n",
    "\n",
    "                detections = image_detections[image_detections['z-index'] == z_index].reset_index().query(\"probability >= {}\".format(probability_threshold))\n",
    "                matched_detection = set()\n",
    "\n",
    "                nodule_id = 0\n",
    "                for bbox in nodule[\"bboxes\"]:\n",
    "                    max_ratio = threshold\n",
    "                    best_detection_id = -1\n",
    "                    number_of_test += 1\n",
    "\n",
    "                    for detection_id, detection in detections.iterrows():\n",
    "                        if detection_id in matched_detection:\n",
    "                            continue\n",
    "\n",
    "                        ratio = compute_overlap_area_ratio(bbox, detection[\"bbox\"])\n",
    "\n",
    "                        if ratio > max_ratio:\n",
    "                            best_detection_id = detection_id\n",
    "                            max_ratio = ratio\n",
    "\n",
    "                    image = cv2.imread(\"{}/{}/z-{}.jpg\".format(image_folder_path, series_id, z_index))\n",
    "                    # add green annotation rect\n",
    "                    image = cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 1)\n",
    "\n",
    "                    if best_detection_id != -1:\n",
    "                        hit_counter += 1\n",
    "                        matched_detection.add(best_detection_id)\n",
    "                        best_detection = detections.iloc[best_detection_id]\n",
    "\n",
    "                        # add red detection rect\n",
    "                        cv2.rectangle(image, (round(best_detection[\"top_left_x\"]), round(best_detection[\"top_left_y\"])), (round(best_detection[\"bottom_right_x\"]), round(best_detection[\"bottom_right_y\"])), (0, 0, 255), 1)\n",
    "\n",
    "                        cv2.imwrite(\"{}/{}-z{}-nodule{}-{}.jpg\".format(detections_output_folder, series_id, z_index, nodule_id, max_ratio), image)\n",
    "                    else:\n",
    "                        cv2.imwrite(\"{}/{}-z{}-not-detected.jpg\".format(detections_output_folder, series_id, z_index), image)\n",
    "\n",
    "                nodule_id += 1\n",
    "\n",
    "        hit_rate = hit_counter / number_of_test\n",
    "        miss_rate_y.append(1 - hit_rate)\n",
    "        miss_rate_x.append(int(epoch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_rate_x = []\n",
    "miss_rate_y = []\n",
    "\n",
    "calculate_mr(threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(25, 5))\n",
    "plt.plot(miss_rate_x, miss_rate_y, label='MR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(miss_rate_x, miss_rate_y)), key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
