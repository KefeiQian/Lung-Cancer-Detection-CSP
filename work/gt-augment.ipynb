{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = open(\"../data/cache/train_gt\", 'rb')\n",
    "train_pickle = pickle.Unpickler(fid, encoding=\"latin1\")\n",
    "train_gt = train_pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = open(\"../data/cache/train_no_gt\", 'rb')\n",
    "train_no_gt_pickle = pickle.Unpickler(fid, encoding=\"latin1\")\n",
    "train_no_gt = train_no_gt_pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/gts\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=1),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['nodule']))\n",
    "\n",
    "vertical_transform = A.Compose([\n",
    "    A.VerticalFlip(p=1),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['nodule']))\n",
    "\n",
    "rotate90_transform = A.Compose([\n",
    "    A.Rotate(limit=(90, 90), p=1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['nodule']))\n",
    "\n",
    "rotate180_transform = A.Compose([\n",
    "    A.Rotate(limit=(180, 180), p=1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['nodule']))\n",
    "\n",
    "rotate270_transform = A.Compose([\n",
    "    A.Rotate(limit=(-90, -90), p=1)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['nodule']))\n",
    "\n",
    "transforms = [horizontal_transform, vertical_transform, rotate90_transform, rotate180_transform,\n",
    "              rotate270_transform]\n",
    "\n",
    "transform_names = [\"h\", \"v\", \"r90\", \"r180\", \"r270\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_safe_transform = A.Compose([\n",
    "    A.Rotate(),\n",
    "    A.RandomSizedBBoxSafeCrop(image_size[0], image_size[1], p = 1),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['nodule']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = (0, 0, 255)\n",
    "\n",
    "def generate_augment_gts():\n",
    "    for gt in tqdm(train_gt):\n",
    "        filepath = gt[\"filepath\"]\n",
    "        filepath = \"../\" + filepath\n",
    "\n",
    "        series_id = filepath.split(\"/\")[-2]\n",
    "\n",
    "        z = filepath.split(\"/\")[-1].split(\".\")[-2]\n",
    "\n",
    "        bboxes = gt[\"bboxes\"]\n",
    "\n",
    "        image = cv2.imread(filepath)\n",
    "\n",
    "        class_labels = ['nodule'] * len(bboxes)\n",
    "\n",
    "        output_folder =  \"{}/{}\".format(output_path, series_id)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        origin_output_path = \"{}/{}-ori.jpg\".format(output_folder, z)\n",
    "        cv2.imwrite(origin_output_path, image)\n",
    "        anno = {'bboxes': bboxes, 'ignoreareas': np.array([]),\n",
    "                'filepath': origin_output_path[3:]}\n",
    "        augment_gts.append(anno)\n",
    "\n",
    "        # cv2.rectangle(image, (bboxes[0][0], bboxes[0][1]),\n",
    "        #               (bboxes[0][2], bboxes[0][3]), color, 1)\n",
    "        #\n",
    "        # cv2.rectangle(image, (bboxes[1][0], bboxes[1][1]),\n",
    "        #               (bboxes[1][2], bboxes[1][3]), color, 1)\n",
    "        #\n",
    "        # cv2.imwrite(\"test/patched.jpg\", image)\n",
    "\n",
    "        for i in range(len(transforms)):\n",
    "            transformed = transforms[i](image=image, bboxes=bboxes, nodule=class_labels)\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_bbox = transformed['bboxes']\n",
    "\n",
    "            for j in range(len(transformed_bbox)):\n",
    "                transformed_bbox[j] = list(map(lambda x: math.ceil(x), transformed_bbox[j]))\n",
    "\n",
    "            output_image_path = \"{}/{}/{}-{}.jpg\".format(output_path, series_id, z, transform_names[i])\n",
    "            anno = {'bboxes': transformed_bbox, 'ignoreareas': np.array([]),\n",
    "                    'filepath': output_image_path[3:]}\n",
    "\n",
    "            # cv2.rectangle(transformed_image, (transformed_bbox[0][0], transformed_bbox[0][1]),\n",
    "            #               (transformed_bbox[0][2], transformed_bbox[0][3]), color, 1)\n",
    "            # cv2.rectangle(transformed_image, (transformed_bbox[1][0], transformed_bbox[1][1]),\n",
    "            #               (transformed_bbox[1][2], transformed_bbox[1][3]), color, 1)\n",
    "            # cv2.imwrite(\"test/{}.jpg\".format(i), transformed_image)\n",
    "            cv2.imwrite(output_image_path, transformed_image)\n",
    "            augment_gts.append(anno)\n",
    "\n",
    "        for i in range(45):\n",
    "            transformed = bbox_safe_transform(image=image, bboxes=bboxes, nodule=class_labels)\n",
    "            bbox_safe_image = transformed['image']\n",
    "            bbox_safe_bbox = transformed['bboxes']\n",
    "\n",
    "            for j in range(len(bbox_safe_bbox)):\n",
    "                bbox_safe_bbox[j] = list(map(lambda x: math.ceil(x), bbox_safe_bbox[j]))\n",
    "\n",
    "            # cropped_image = cv2.rectangle(cropped_image, (\n",
    "            #     bbox_safe_bbox[0][0], bbox_safe_bbox[0][1]), (bbox_safe_bbox[0][2],\n",
    "            #                                                   bbox_safe_bbox[0][3]),\n",
    "            #                                                           color, 1)\n",
    "            # if len(bbox_safe_bbox) > 1:\n",
    "            #     cropped_image  = cv2.rectangle(cropped_image, (bbox_safe_bbox[1][0], bbox_safe_bbox[1][1]), (bbox_safe_bbox[1][2],bbox_safe_bbox[1][3]), color, 1)\n",
    "            #     print(bbox_safe_bbox[1])\n",
    "            #     cv2.imwrite(\"test/croped-{}.jpg\".format(i + 1), cropped_image)\n",
    "\n",
    "            output_image_path = \"{}/{}/{}-cropped-{}.jpg\".format(output_path, series_id, z, i + 1)\n",
    "            anno = {'bboxes': bbox_safe_bbox, 'ignoreareas': np.array([]),\n",
    "                    'filepath': output_image_path[3:]}\n",
    "\n",
    "            augment_gts.append(anno)\n",
    "\n",
    "            cv2.imwrite(output_image_path, bbox_safe_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_no_gts():\n",
    "    no_gt_ratio = 2\n",
    "    no_gt_size = math.ceil(len(augment_gts) * no_gt_ratio)\n",
    "    image_data_no_gt_sampled = random.sample(train_no_gt, no_gt_size)\n",
    "    image_data_no_gt_sampled_df = pd.DataFrame(image_data_no_gt_sampled)\n",
    "\n",
    "    no_gt_cache_sampled_path = \"../data/cache/train_no_gt_sample\"\n",
    "    image_data_no_gt_sampled_df.set_index(\"filepath\", inplace=True)\n",
    "    image_data_no_gt_sampled_df.to_csv(\"output/no_gt_sample.csv\")\n",
    "\n",
    "    with open(no_gt_cache_sampled_path, 'wb') as fid:\n",
    "        pickle.dump(image_data_no_gt_sampled, fid, 2)\n",
    "        fid.close()\n",
    "\n",
    "    print(len(image_data_no_gt_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_gts = []\n",
    "\n",
    "generate_augment_gts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(augment_gts)\n",
    "df.set_index(\"filepath\", inplace=True)\n",
    "df.to_csv(\"output/gt-augment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_gt_cache_path = \"../data/cache/train_gt_augment\"\n",
    "with open(augment_gt_cache_path, 'wb') as fid:\n",
    "    pickle.dump(augment_gts, fid, 2)\n",
    "    fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_no_gts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
