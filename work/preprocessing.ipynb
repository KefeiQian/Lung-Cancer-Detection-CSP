{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_subset_id = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "download_folder = \"../downloads\"\n",
    "download_data_folder = \"../downloads/data\"\n",
    "download_mask_folder = \"../downloads/seg-lungs-LUNA16\"\n",
    "\n",
    "output_nodules_folder = \"output/nodules\"\n",
    "\n",
    "data_image_folder = \"../data/images\"\n",
    "\n",
    "\n",
    "\n",
    "mhd_info_csv_path = \"data/mhd_info.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in [output_nodules_folder, data_image_folder]:\n",
    "    if not os.path.exists(p):\n",
    "        os.makedirs(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "image_size = (512, 512)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                           seriesuid      coordX      coordY  \\\n0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -128.699421 -175.319272   \n1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  103.783651 -211.925149   \n2  1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...   69.639017 -140.944586   \n3  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...  -24.013824  192.102405   \n4  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...    2.441547  172.464881   \n\n       coordZ  diameter_mm  \n0 -298.387506     5.651471  \n1 -227.121250     4.224708  \n2  876.374496     5.786348  \n3 -391.081276     8.143262  \n4 -405.493732    18.545150  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seriesuid</th>\n      <th>coordX</th>\n      <th>coordY</th>\n      <th>coordZ</th>\n      <th>diameter_mm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n      <td>-128.699421</td>\n      <td>-175.319272</td>\n      <td>-298.387506</td>\n      <td>5.651471</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n      <td>103.783651</td>\n      <td>-211.925149</td>\n      <td>-227.121250</td>\n      <td>4.224708</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...</td>\n      <td>69.639017</td>\n      <td>-140.944586</td>\n      <td>876.374496</td>\n      <td>5.786348</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>-24.013824</td>\n      <td>192.102405</td>\n      <td>-391.081276</td>\n      <td>8.143262</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>2.441547</td>\n      <td>172.464881</td>\n      <td>-405.493732</td>\n      <td>18.545150</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_path = \"../downloads/annotations.csv\"\n",
    "annotations_df = pd.read_csv(annotations_path, delimiter=\",\")\n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "candidates_path = \"../downloads/candidates_V2.csv\"\n",
    "candidates_df = pd.read_csv(candidates_path, delimiter=\",\")\n",
    "gt_candidates_df = candidates_df[candidates_df[\"class\"] == 1]\n",
    "no_gt_candidates_df = candidates_df[candidates_df[\"class\"] != 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              seriesuid      coordX  \\\n436   1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  104.083933   \n1009  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -128.982091   \n2053  1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...   69.974375   \n3633  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...    1.790000   \n3707  1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...    1.859783   \n\n          coordY      coordZ  class  \n436  -211.755826 -227.017987      1  \n1009 -175.176790 -298.510193      1  \n2053 -141.066875  876.777280      1  \n3633  166.340000 -408.880000      1  \n3707  172.221534 -405.366447      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seriesuid</th>\n      <th>coordX</th>\n      <th>coordY</th>\n      <th>coordZ</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>436</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n      <td>104.083933</td>\n      <td>-211.755826</td>\n      <td>-227.017987</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1009</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n      <td>-128.982091</td>\n      <td>-175.176790</td>\n      <td>-298.510193</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2053</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100398138793...</td>\n      <td>69.974375</td>\n      <td>-141.066875</td>\n      <td>876.777280</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3633</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>1.790000</td>\n      <td>166.340000</td>\n      <td>-408.880000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3707</th>\n      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100621383016...</td>\n      <td>1.859783</td>\n      <td>172.221534</td>\n      <td>-405.366447</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_candidates_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image[image > 400] = 400\n",
    "    image[image < -1000] = -1000\n",
    "\n",
    "    max_hu = image.max()\n",
    "    min_hu = image.min()\n",
    "    image = (image - min_hu) / (max_hu - min_hu) * 255\n",
    "    image = np.round(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def world_to_voxel_coord(world_coord, origin, spacing):\n",
    "    stretched_voxel_coord = np.absolute(world_coord - origin)\n",
    "    voxel_coord = stretched_voxel_coord / spacing\n",
    "    return voxel_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def extract_mhd_file_info(subset_id, series_id):\n",
    "    mhd_file_path = \"{}/subset{}/{}.mhd\".format(download_data_folder, subset_id, series_id)\n",
    "    mask_file_path = \"{}/{}.mhd\".format(download_mask_folder, series_id)\n",
    "\n",
    "    itk_image = sitk.ReadImage(mhd_file_path, sitk.sitkFloat32)\n",
    "    ct_scans = sitk.GetArrayFromImage(itk_image)\n",
    "\n",
    "    origins = np.array(list(reversed(itk_image.GetOrigin())))\n",
    "    spacings = np.array(list(reversed(itk_image.GetSpacing())))\n",
    "\n",
    "    direction = itk_image.GetDirection()\n",
    "    direction = np.array(list(map(lambda x: round(x), direction)))\n",
    "\n",
    "    if np.any(direction != np.array([1, 0, 0, 0, 1, 0, 0, 0, 1])):\n",
    "        is_flip = True\n",
    "    else:\n",
    "        is_flip = False\n",
    "\n",
    "    ct_image_folder = \"{}/{}\".format(data_image_folder, series_id)\n",
    "\n",
    "    mhd_info = {\n",
    "        \"mhd_file_path\": mhd_file_path,\n",
    "        \"mask_file_path\": mask_file_path,\n",
    "        \"subset_id\": subset_id,\n",
    "        \"series_id\": series_id,\n",
    "        \"total_images\": ct_scans.shape[0],\n",
    "        \"origins\": origins.tolist(),\n",
    "        \"spacings\": spacings.tolist(),\n",
    "        \"is_flip\": is_flip,\n",
    "        \"ct_image_folder\": ct_image_folder\n",
    "    }\n",
    "\n",
    "    return mhd_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def extract_ct_images(mhd_info, mask=False):\n",
    "    mhd_file_path = mhd_info[\"mhd_file_path\"]\n",
    "    mask_file_path = mhd_info[\"mask_file_path\"]\n",
    "    is_flip = mhd_info[\"is_flip\"]\n",
    "    total_images = mhd_info[\"total_images\"]\n",
    "    ct_image_folder = mhd_info[\"ct_image_folder\"]\n",
    "\n",
    "    ct_scans = sitk.GetArrayFromImage(sitk.ReadImage(mhd_file_path, sitk.sitkFloat32))\n",
    "    if mask:\n",
    "        masks = sitk.GetArrayFromImage(sitk.ReadImage(mask_file_path, sitk.sitkFloat32))\n",
    "\n",
    "    if is_flip:\n",
    "        ct_scans = ct_scans[:, ::-1, ::-1]\n",
    "        if mask:\n",
    "            masks = masks[:, ::-1, ::-1]\n",
    "\n",
    "    ct_scans = normalize(ct_scans)\n",
    "    ct_scans = ct_scans.astype(np.uint8)\n",
    "    if mask:\n",
    "        masks = masks.astype(np.uint8)\n",
    "\n",
    "    if not os.path.exists(ct_image_folder):\n",
    "        os.makedirs(ct_image_folder)\n",
    "\n",
    "    for z in range(0, total_images):\n",
    "        if mask:\n",
    "            masked_image = cv2.bitwise_and(ct_scans[z], ct_scans[z], mask=masks[z])\n",
    "            colored_image = cv2.cvtColor(masked_image, cv2.COLOR_GRAY2RGB)\n",
    "        else:\n",
    "            colored_image = cv2.cvtColor(ct_scans[z], cv2.COLOR_GRAY2RGB)\n",
    "        cv2.imwrite(\"{}/z-{}.jpg\".format(ct_image_folder, z), colored_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def generate_train_test_cache(mhd_info):\n",
    "    subset_id = mhd_info[\"subset_id\"]\n",
    "    series_id = mhd_info[\"series_id\"]\n",
    "    origins = mhd_info[\"origins\"]\n",
    "    spacings = mhd_info[\"spacings\"]\n",
    "    is_flip = mhd_info[\"is_flip\"]\n",
    "    total_images = mhd_info[\"total_images\"]\n",
    "    ct_image_folder = mhd_info[\"ct_image_folder\"]\n",
    "\n",
    "    spacings = np.array(json.loads(spacings))\n",
    "    origins = np.array(json.loads(origins))\n",
    "\n",
    "    annotations = annotations_df[annotations_df[\"seriesuid\"] == series_id]\n",
    "\n",
    "    nodules_annotation = []\n",
    "    for _, row in annotations.iterrows():\n",
    "        world_x = row[\"coordX\"]\n",
    "        world_y = row[\"coordY\"]\n",
    "        world_z = row[\"coordZ\"]\n",
    "        diameter = row[\"diameter_mm\"]\n",
    "\n",
    "        world_coord = np.array([float(world_z), float(world_y), float(world_x)])\n",
    "        voxel_coord = world_to_voxel_coord(world_coord, origins, spacings)\n",
    "\n",
    "        voxel_z, voxel_y, voxel_x = voxel_coord\n",
    "        if is_flip:\n",
    "            voxel_x = image_size[0] - voxel_x\n",
    "            voxel_y = image_size[1] - voxel_y\n",
    "\n",
    "        radius = diameter / spacings[2] / 2\n",
    "\n",
    "        annotation = {\"z\": round(voxel_z), 'bbox':\n",
    "            np.array([\n",
    "                max(round(voxel_x - radius), 0),\n",
    "                max(round(voxel_y - radius), 0),\n",
    "                min(round(voxel_x + radius), image_size[0] - 1),\n",
    "                min(round(voxel_y + radius), image_size[1] - 1)\n",
    "            ]), 'ignoreareas': np.array([])}\n",
    "        nodules_annotation.append(annotation)\n",
    "    nodules_df = pd.DataFrame(nodules_annotation)\n",
    "\n",
    "    no_gt_df = no_gt_candidates_df[no_gt_candidates_df[\"seriesuid\"] == series_id]\n",
    "    no_gt_z = set()\n",
    "    for _, row in no_gt_df.iterrows():\n",
    "        world_x = row[\"coordX\"]\n",
    "        world_y = row[\"coordY\"]\n",
    "        world_z = row[\"coordZ\"]\n",
    "\n",
    "        world_coord = np.array([float(world_z), float(world_y), float(world_x)])\n",
    "        voxel_coord = world_to_voxel_coord(world_coord, origins, spacings)\n",
    "\n",
    "        voxel_z, voxel_y, voxel_x = voxel_coord\n",
    "        no_gt_z.add(round(voxel_z))\n",
    "\n",
    "    for z in range(0, total_images):\n",
    "        filepath = \"{}/z-{}.jpg\".format(ct_image_folder[3:], z)\n",
    "        bboxes = []\n",
    "        ignore_areas = np.array([])\n",
    "\n",
    "        if len(nodules_annotation) != 0:\n",
    "            for _, nodule in nodules_df[nodules_df[\"z\"] == z].iterrows():\n",
    "                bboxes.append(nodule[\"bbox\"])\n",
    "\n",
    "        anno = {'bboxes': np.array(bboxes), 'ignoreareas': ignore_areas,\n",
    "                'filepath': filepath}\n",
    "\n",
    "        if len(bboxes) != 0:\n",
    "            if subset_id != test_subset_id:\n",
    "                image_data_gt.append(anno)\n",
    "            else:\n",
    "                image_data_test.append(anno)\n",
    "        else:\n",
    "            if z in no_gt_z:\n",
    "                image_data_no_gt.append(anno)\n",
    "\n",
    "            # if subset_id == test_subset_id:\n",
    "            #     image_data_test.append(anno)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "subset: 100%|██████████| 10/10 [01:51<00:00, 11.13s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_image_folder):\n",
    "    os.makedirs(data_image_folder)\n",
    "\n",
    "image_data_gt, image_data_no_gt, image_data_test = [], [], []\n",
    "\n",
    "if os.path.exists(mhd_info_csv_path):\n",
    "    mhd_info_df = pd.read_csv(mhd_info_csv_path)\n",
    "else:\n",
    "    mhd_infos = []\n",
    "\n",
    "for subset_id in tqdm(range(0, 10), desc=\"subset\"):\n",
    "    current_folder = os.listdir(\"{}/subset{}\".format(download_data_folder, subset_id))\n",
    "\n",
    "    for file in current_folder:\n",
    "        if file.endswith(\".mhd\"):\n",
    "            series_id = re.search(r'(.*)\\.mhd', file).group(1)\n",
    "            if os.path.exists(mhd_info_csv_path):\n",
    "                mhd_info = mhd_info_df[mhd_info_df[\"series_id\"] == series_id].iloc[0]\n",
    "            else:\n",
    "                mhd_info = extract_mhd_file_info(subset_id, series_id)\n",
    "                mhd_infos.append(mhd_info)\n",
    "\n",
    "            # extract_ct_images(mhd_info, mask=False)\n",
    "            generate_train_test_cache(mhd_info)\n",
    "\n",
    "if not os.path.exists(mhd_info_csv_path):\n",
    "    mhd_info_df = pd.DataFrame(mhd_infos)\n",
    "    mhd_info_df.to_csv(mhd_info_csv_path, index=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_data_gt_df = pd.DataFrame(image_data_gt)\n",
    "image_data_no_gt_df = pd.DataFrame(image_data_no_gt)\n",
    "image_data_test_df = pd.DataFrame(image_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "image_data_gt_df.set_index(\"filepath\", inplace=True)\n",
    "image_data_no_gt_df.set_index(\"filepath\", inplace=True)\n",
    "image_data_test_df.set_index(\"filepath\", inplace=True)\n",
    "\n",
    "image_data_gt_df.to_csv(\"output/gt.csv\")\n",
    "image_data_no_gt_df.to_csv(\"output/no_gt.csv\")\n",
    "image_data_test_df.to_csv(\"output/test.csv\")\n",
    "\n",
    "gt_cache_path = \"../data/cache/train_gt\"\n",
    "no_gt_cache_path = \"../data/cache/train_no_gt\"\n",
    "test_cache_path = \"../data/cache/test\"\n",
    "\n",
    "with open(gt_cache_path, 'wb') as fid:\n",
    "    pickle.dump(image_data_gt, fid, 2)\n",
    "with open(no_gt_cache_path, 'wb') as fid:\n",
    "    pickle.dump(image_data_no_gt, fid, 2)\n",
    "with open(test_cache_path, 'wb') as fid:\n",
    "    pickle.dump(image_data_test, fid, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "152125"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lung-Cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d4e508bcdf8c60a886d154242a7d048eb1090ffddac0cfb1f3922d8edcb8935"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
